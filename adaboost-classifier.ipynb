{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1731,"sourceType":"datasetVersion","datasetId":945}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\nAdaboost:\nAn ensemble model is a composite model which combines a series of low performing or weak classifiers with the aim of creating a strong classifier\nThese ensemble models offer greater accuracy than individual or base classifiers\nensemble learning methods are meta-algorithms that combine several machine learning algorithms into a single predictive model to increase performance\nEnsemble models are created according to some specific criterion:\n1.Bagging:They can be created to decrease model variance using bagging approach.\n2. Boosting:They can be created to decrease model bias using a boosting approach\n3. Stacking:They can be created to improve model predictions using stacking approach\n\n'''","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-02T11:58:58.919988Z","iopub.execute_input":"2024-01-02T11:58:58.920608Z","iopub.status.idle":"2024-01-02T11:58:58.929597Z","shell.execute_reply.started":"2024-01-02T11:58:58.920560Z","shell.execute_reply":"2024-01-02T11:58:58.928225Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'\\nAdaboost:\\nAn ensemble model is a composite model which combines a series of low performing or weak classifiers with the aim of creating a strong classifier\\nThese ensemble models offer greater accuracy than individual or base classifiers\\nensemble learning methods are meta-algorithms that combine several machine learning algorithms into a single predictive model to increase performance\\nEnsemble models are created according to some specific criterion:\\n1.Bagging:They can be created to decrease model variance using bagging approach.\\n2. Boosting:They can be created to decrease model bias using a boosting approach\\n3. Stacking:They can be created to improve model predictions using stacking approach\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:58.932131Z","iopub.execute_input":"2024-01-02T11:58:58.932917Z","iopub.status.idle":"2024-01-02T11:58:58.945819Z","shell.execute_reply.started":"2024-01-02T11:58:58.932873Z","shell.execute_reply":"2024-01-02T11:58:58.944867Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/iris-datasets/Iris.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:58.947834Z","iopub.execute_input":"2024-01-02T11:58:58.949394Z","iopub.status.idle":"2024-01-02T11:58:58.979800Z","shell.execute_reply.started":"2024-01-02T11:58:58.949345Z","shell.execute_reply":"2024-01-02T11:58:58.978437Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n0      1            5.1           3.5            1.4           0.2   \n1      2            4.9           3.0            1.4           0.2   \n2      3            4.7           3.2            1.3           0.2   \n3      4            4.6           3.1            1.5           0.2   \n4      5            5.0           3.6            1.4           0.2   \n..   ...            ...           ...            ...           ...   \n145  146            6.7           3.0            5.2           2.3   \n146  147            6.3           2.5            5.0           1.9   \n147  148            6.5           3.0            5.2           2.0   \n148  149            6.2           3.4            5.4           2.3   \n149  150            5.9           3.0            5.1           1.8   \n\n            Species  \n0       Iris-setosa  \n1       Iris-setosa  \n2       Iris-setosa  \n3       Iris-setosa  \n4       Iris-setosa  \n..              ...  \n145  Iris-virginica  \n146  Iris-virginica  \n147  Iris-virginica  \n148  Iris-virginica  \n149  Iris-virginica  \n\n[150 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>146</td>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>147</td>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>150</td>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:58.981563Z","iopub.execute_input":"2024-01-02T11:58:58.982008Z","iopub.status.idle":"2024-01-02T11:58:58.997259Z","shell.execute_reply.started":"2024-01-02T11:58:58.981962Z","shell.execute_reply":"2024-01-02T11:58:58.995686Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             150 non-null    int64  \n 1   SepalLengthCm  150 non-null    float64\n 2   SepalWidthCm   150 non-null    float64\n 3   PetalLengthCm  150 non-null    float64\n 4   PetalWidthCm   150 non-null    float64\n 5   Species        150 non-null    object \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 7.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.000506Z","iopub.execute_input":"2024-01-02T11:58:59.000937Z","iopub.status.idle":"2024-01-02T11:58:59.014001Z","shell.execute_reply.started":"2024-01-02T11:58:59.000896Z","shell.execute_reply":"2024-01-02T11:58:59.012688Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"Id               0\nSepalLengthCm    0\nSepalWidthCm     0\nPetalLengthCm    0\nPetalWidthCm     0\nSpecies          0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.015571Z","iopub.execute_input":"2024-01-02T11:58:59.015919Z","iopub.status.idle":"2024-01-02T11:58:59.026777Z","shell.execute_reply.started":"2024-01-02T11:58:59.015888Z","shell.execute_reply":"2024-01-02T11:58:59.025455Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Id                 int64\nSepalLengthCm    float64\nSepalWidthCm     float64\nPetalLengthCm    float64\nPetalWidthCm     float64\nSpecies           object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf['Species']=le.fit_transform(df['Species'])","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.028023Z","iopub.execute_input":"2024-01-02T11:58:59.028347Z","iopub.status.idle":"2024-01-02T11:58:59.034803Z","shell.execute_reply.started":"2024-01-02T11:58:59.028319Z","shell.execute_reply":"2024-01-02T11:58:59.033967Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.035793Z","iopub.execute_input":"2024-01-02T11:58:59.036141Z","iopub.status.idle":"2024-01-02T11:58:59.058983Z","shell.execute_reply.started":"2024-01-02T11:58:59.036113Z","shell.execute_reply":"2024-01-02T11:58:59.057833Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n0   1            5.1           3.5            1.4           0.2        0\n1   2            4.9           3.0            1.4           0.2        0\n2   3            4.7           3.2            1.3           0.2        0\n3   4            4.6           3.1            1.5           0.2        0\n4   5            5.0           3.6            1.4           0.2        0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x = df.drop(['Species'], axis=1)\ny = df['Species']","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.061073Z","iopub.execute_input":"2024-01-02T11:58:59.061481Z","iopub.status.idle":"2024-01-02T11:58:59.070286Z","shell.execute_reply.started":"2024-01-02T11:58:59.061449Z","shell.execute_reply":"2024-01-02T11:58:59.068979Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split dataset into training set and test set\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=23)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.073886Z","iopub.execute_input":"2024-01-02T11:58:59.075370Z","iopub.status.idle":"2024-01-02T11:58:59.083094Z","shell.execute_reply.started":"2024-01-02T11:58:59.075327Z","shell.execute_reply":"2024-01-02T11:58:59.082333Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"'''\nEstimator is the learning algorithm to use to train the weak models\nn_estimators is the number of models to iteratively train\nlearning_rate is the contribution of each model to the weights and defaults to 1\n'''","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.084509Z","iopub.execute_input":"2024-01-02T11:58:59.085671Z","iopub.status.idle":"2024-01-02T11:58:59.096302Z","shell.execute_reply.started":"2024-01-02T11:58:59.085632Z","shell.execute_reply":"2024-01-02T11:58:59.094937Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'\\nEstimator is the learning algorithm to use to train the weak models\\nn_estimators is the number of models to iteratively train\\nlearning_rate is the contribution of each model to the weights and defaults to 1\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# Import the AdaBoost classifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# Create adaboost classifer object\nabc = AdaBoostClassifier(n_estimators=50, learning_rate=1, random_state=10)\n\n# Train Adaboost Classifer\nmodel1 = abc.fit(x_train, y_train)\n\n\n#Predict the response for test dataset\ny_pred = model1.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.100427Z","iopub.execute_input":"2024-01-02T11:58:59.101011Z","iopub.status.idle":"2024-01-02T11:58:59.224874Z","shell.execute_reply.started":"2024-01-02T11:58:59.100971Z","shell.execute_reply":"2024-01-02T11:58:59.223519Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# calculate and print model accuracy\nprint(\"AdaBoost Classifier Model Accuracy:\", accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.226107Z","iopub.execute_input":"2024-01-02T11:58:59.226461Z","iopub.status.idle":"2024-01-02T11:58:59.234906Z","shell.execute_reply.started":"2024-01-02T11:58:59.226433Z","shell.execute_reply":"2024-01-02T11:58:59.233480Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"AdaBoost Classifier Model Accuracy: 0.9777777777777777\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n\n# import Support Vector Classifier\nfrom sklearn.svm import SVC\n\n\n# import scikit-learn metrics module for accuracy calculation\nfrom sklearn.metrics import accuracy_score\nsvc=SVC(probability=True, kernel='linear')\n\n\n# create adaboost classifer object\nabc =AdaBoostClassifier(n_estimators=50, estimator=svc,learning_rate=1, random_state=0)\n\n\n# train adaboost classifer\nmodel2 = abc.fit(x_train, y_train)\n\n\n# predict the response for test dataset\ny_pred = model2.predict(x_test)\n\n\n# calculate and print model accuracy\nprint(\"Model Accuracy with SVC Base Estimator:\",accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.236324Z","iopub.execute_input":"2024-01-02T11:58:59.236625Z","iopub.status.idle":"2024-01-02T11:58:59.257192Z","shell.execute_reply.started":"2024-01-02T11:58:59.236598Z","shell.execute_reply":"2024-01-02T11:58:59.255911Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Model Accuracy with SVC Base Estimator: 0.9777777777777777\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nDecision Tree Base Estimator is getting better accuracy then SVC Base Estimator.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-01-02T11:58:59.258434Z","iopub.execute_input":"2024-01-02T11:58:59.258739Z","iopub.status.idle":"2024-01-02T11:58:59.266844Z","shell.execute_reply.started":"2024-01-02T11:58:59.258712Z","shell.execute_reply":"2024-01-02T11:58:59.265453Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'\\nDecision Tree Base Estimator is getting better accuracy then SVC Base Estimator.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}